<!DOCTYPE HTML>
<html lang="en">


<!-- NOTE: Do not scrape the code from this page directly, as it includes analytics tags. You are welcome to use the HTML in this page, but please do so by cloning the github repo linked at the bottom. -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-QSFRPR5L7E"></script> -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-QSFRPR5L7E');
</script>

<head>
  <!-- Google Tag Manager -->
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-KCT7G6PM');</script>
  <!-- End Google Tag Manager -->
  <meta name="google-site-verification" content="33YsupeCdDQ-bfIMjbNswWCJqA_2Ysw32OzerQgpyv4" />
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Sara Rojas</title>

  <meta name="author" content="Sara Rojas">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KCT7G6PM"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Sara Rojas
                  </p>
                  <p>
                    I'm a PhD Candidate at <a
                      href="https://cemse.kaust.edu.sa/ece/people/person/sara-rojas-martinez">KAUST</a> in Saudi Arabia,
                    under the supervision of Professor <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>.
                  </p>
                  <p>
                    Experience in 3D computer vision: neural rendering, 3D reconstruction, and 3D-based recognition tasks
                  </p>
                  <p>
                  </p>
                  <p>
                    I've recently completed a research internship at <strong>Naver Labs Europe</strong>, where I worked on extending <a href="https://github.com/naver/mast3r">MAST3R</a> to better understand humans in-the-wild. I was fortunate to be advised by <a href="https://europe.naverlabs.com/people_user_naverlabs/gregory-rogez/">Gregory Rogez</a>, <a href="https://europe.naverlabs.com/people_user_naverlabs/matthieu-armando/">Matthieu Armando</a>, and <a href="https://europe.naverlabs.com/people_user_naverlabs/vincent-leroy/">Vincent Leroy</a>.
                  </p>

                  <p>
                    Prior to that, I interned at <strong>Adobe Research</strong>, where I worked under the guidance of <a href="https://www.kalyans.org/">Kalyan Sunkavalli</a>. I also collaborated with <strong>Reality Labs at Meta</strong> in Zurich, mentored by <a href="https://www.albertpumarola.com/">Albert Pumarola</a> and <a href="https://www.alithabet.com/">Ali Thabet</a>. Earlier, I conducted research at the <strong>University of Southern California</strong> with <a href="https://scholar.google.com/citations?user=l_kICksAAAAJ&hl=en">Autumn Kulaga</a>.
                  </p>
                  <!-- <p style="color: rgb(212, 105, 237);">
                    I'm expected to graduate in Dec 2025 and am currently on the job market. If you have any opportunities, I would greatly appreciate it if you could drop me an email. Thank you!
                  </p> -->

                  <p style="text-align:center">
                    <a href="mailto:sara.rojasmartinez@kaust.edu.sa">Email</a> &nbsp;/&nbsp;
                    <a href="data/SaraRojas-CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=7vnDKiwAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/SarisRo">X</a> &nbsp;/&nbsp;
                    <a href="https://github.com/sararoma95">Github</a>
                  </p>
                   <p style="text-align:center">
                   Last updated: <strong>Nov 2025</strong>
                   </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/SaraRojas.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/SaraRojas.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I’m interested in 3D computer vision, deep learning, generative AI, and image processing. 
                    Most of my research focuses on NeRF and its applications, including scene editing and efficiency. 
                    Lately, I’ve been working on 3D reconstruction.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='datenerf_image'><img src='images/datenerf.png' width=100%></div> -->
                    <img src='images/hamst3r.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('datenerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('datenerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://europe.naverlabs.com/research/publications/hamst3r-human-aware-multi-view-stereo-3d-reconstruction/">
                    <span class="papertitle">HAMSt3R: Human-Aware Multi-view Stereo 3D Reconstruction</span>
                  </a>
                  <br>
                  <strong>Sara Rojas</strong>,
                  <a href="https://europe.naverlabs.com/people_user_naverlabs/matthieu-armando/">Matthieu Armando</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <a href="https://europe.naverlabs.com/people_user_naverlabs/philippe-weinzaepfel/">Philippe Weinzaepfel</a>,
                  <a href="https://europe.naverlabs.com/people_user_naverlabs/vincent-leroy/">Vincent Leroy</a>,
                  <a href="https://europe.naverlabs.com/people_user_naverlabs/gregory-rogez/">Gregory Rogez</a>,
                  <br>
                  <!-- <em>ICCV</em>, 2023 -->
                  <em>ICCV</em>, 2025
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://europe.naverlabs.com/research/publications/hamst3r-human-aware-multi-view-stereo-3d-reconstruction/">Project Page</a>
                  /
                  <a href="https://arxiv.org/abs/2508.16433">arXiv</a>
                  <p></p>
                  <p>
                    HAMSt3R is a feed-forward method for joint human and scene 3D reconstruction from sparse images, 
                    using a strong encoder and specialized heads. It handles human-centric scenarios effectively 
                    while preserving strong general 3D performance.
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='datenerf_image'><img src='images/datenerf.png' width=100%></div> -->
                    <img src='images/unmixnerf.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('datenerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('datenerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://factral.co/UnMix-NeRF/">
                    <span class="papertitle">UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields</span>
                  </a>
                  <br>
                  <a href="https://github.com/Factral">Fabian Perez</a>,
                  <strong>Sara Rojas</strong>,
                  <a href="https://carloshinojosa.me/">Carlos Hinojosa</a>,
                  <a href="https://www.hfarueda.com/"> Hoover Rueda-Chacón</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <br>
                  <!-- <em>ICCV</em>, 2023 -->
                  <em>ICCV</em>, 2025
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://factral.co/UnMix-NeRF//">Project Page</a>
                  /
                  <a href="https://arxiv.org/pdf/2506.21884">arXiv</a>
                  /
                  <a href="https://github.com/Factral/UnMix-NeRF">Code</a>
                  <p></p>
                  <p>
                    We propose UnMix-NeRF, the first method integrating spectral unmixing into NeRF, 
                    enabling hyperspectral view synthesis, accurate unsupervised material segmentation, 
                    and intuitive material-based scene editing, significantly outperforming existing methods.
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/fourbench.gif' width=100%>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://wenxuanzhu1103.github.io/4dbench.github.io/">
                    <span class="papertitle">4D-Bench: Benchmarking Multi-modal Large Language Models for 4D Object Understanding</span>
                  </a>
                  <br>
                  <a href="https://wenxuanzhu1103.github.io/">Wenxuan Zhu</a>,
                 
                  <a href="https://scholar.google.com/citations?user=xBiftlUAAAAJ&hl=en">Bing Li</a>,
                  Cheng Zheng,
                  <a href="https://scholar.google.com/citations?user=ksCEO0IAAAAJ&hl=en">Jinjie Mai</a>,
                  Jun Chen,
                  Letian Jiang,
                   <a href="https://abdullahamdi.com/">Abdullah Hamdi</a>,
                  <strong>Sara Rojas</strong>,
                  Chia-Wen Lin,
                  Mohamed Elhoseiny,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>
                  <br>
                  <em>ICCV</em>, 2025
                  <br>
                  <a href="https://wenxuanzhu1103.github.io/4dbench.github.io/">Project Page</a>
                  /
                  <a href="https://arxiv.org/abs/2503.17827">arXiv</a>
                  /
                  <a href="https://github.com/WenxuanZhu1103/4D-Bench">Code</a>
                  <p></p>
                  <p>
                    4D-Bench introduces the first large-scale benchmark for evaluating multi-modal large language models 
                    on 4D object understanding, providing diverse tasks and datasets to advance reasoning about dynamic, 
                    temporally-evolving 3D data.
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='datenerf_image'><img src='images/datenerf.png' width=100%></div> -->
                    <img src='images/datenerf.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('datenerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('datenerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://datenerf.github.io/DATENeRF/">
                    <span class="papertitle">DATENeRF: Depth-Aware Text-based Editing of NeRFs</span>
                  </a>
                  <br>
                  <strong>Sara Rojas</strong>,
                  <a href="https://julienphilip.com/">Julien Philip</a>,
                  <a href="https://kai-46.github.io/website/">Kai Zhang</a>,
                  <a href="https://sai-bi.github.io/">Sai Bi</a>,
                  <a href="https://luanfujun.com/">Fujun Luan</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <a href="http://www.kalyans.org/">Kalyan Sunkavalli</a>,
                  <br>
                  <!-- <em>ICCV</em>, 2023 -->
                  <em>ECCV</em>, 2024
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://datenerf.github.io/DATENeRF/">Project Page</a>
                  /
                  <a href="https://arxiv.org/abs/2404.04526">arXiv</a>
                  <p></p>
                  <p>
                    We introduce an inpainting approach that leverages the depth information of NeRF scenes to
                    distribute 2D edits across different images, ensuring robustness against errors and resampling
                    challenges.
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='datenerf_image'><img src='images/datenerf.png' width=100%></div> -->
                    <img src='images/tracknerf.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('datenerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('datenerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://tracknerf.github.io/">
                    <span class="papertitle">TrackNeRF: Bundle Adjusting NeRF from Sparse and Noisy Views via Feature Tracks</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=ksCEO0IAAAAJ&hl=en">Jinjie Mai</a>,
                  <a href="https://ivul.kaust.edu.sa/profiles/wenxuan-zhu">Wenxuan Zhu</a>,
                  <strong>Sara Rojas</strong>,
                  <a href="https://scholar.google.com/citations?user=DWis350AAAAJ&hl=en">Jesus Zarzar</a>,
                  <a href="https://abdullahamdi.com/">Abdullah Hamdi</a>,
                  <a href="https://guochengqian.github.io/">Guocheng Qian</a>,
                  <a href="https://scholar.google.com/citations?user=xBiftlUAAAAJ&hl=en">Bing Li</a>,
                  <a href="https://www.silviogiancola.com/">Silvio Giancola</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem </a>,
                  <br>
                  <!-- <em>ICCV</em>, 2023 -->
                  <em>ECCV</em>, 2024
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://tracknerf.github.io/">Project Page</a>
                  /
                  <a href="https://arxiv.org/abs/2408.10739">arXiv</a>
                  <p></p>
                  <p>
                    TrackNeRF enhances NeRF reconstruction under sparse and noisy poses by enforcing global 3D consistency 
                    via feature tracks across views, inspired by bundle adjustment. It outperforms prior methods like BARF and SPARF, 
                    setting a new benchmark in challenging scenarios.
                  </p>
                </td>
              </tr>
              
              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='smerf_image'><img src='images/re-rend_2.gif' width=100%></div> -->
                    <img src='images/re-rend.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/sararoma95/Re-ReND">
                    <span class="papertitle">Re-ReND: Real-time rendering of nerfs across devices</span>
                  </a>
                  <br>
                  <strong>Sara Rojas</strong>,
                  <a href="https://scholar.google.com/citations?user=DWis350AAAAJ&hl=en">Jesus Zarzar</a>,
                  <a href="https://scholar.google.com/citations?user=zBbUubUAAAAJ&hl=en">Juan C. Perez</a>,
                  <a href="https://scholar.google.de/citations?user=3JmMPIEAAAAJ&hl=en">Artsiom Sanakoyeu</a>,
                  <a href="https://www.alithabet.com/">Ali Thabet</a>,
                  <a href="https://www.albertpumarola.com/">Albert Pumarola</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <br>
                  <em>ICCV</em>, 2023
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://github.com/sararoma95/Re-ReND">Github Repo</a>
                  /
                  <a href="https://arxiv.org/abs/2303.08717">arXiv</a>
                  <p></p>
                  <p>
                    Re-ReND distills the NeRF by extracting the learned density into a mesh, while the
                    learned color information is factorized into a set of matrices that represent the scene's light
                    field. Re-ReND can achieve over a 2.6-fold increase in rendering speed versus the SOTA.
                  </p>
                </td>
              </tr>


              <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='nuvo_image'><video width=100% muted autoplay loop>
                        <source src="images/segnerf.gif" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div> -->
                    <!-- <div class="two" id='nuvo_image'>
                      <img src='images/segnerf.png' width=100%>
                    </div> -->
                    <img src='images/segnerf.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function nuvo_start() {
                      document.getElementById('nuvo_image').style.opacity = "1";
                    }

                    function nuvo_stop() {
                      document.getElementById('nuvo_image').style.opacity = "0";
                    }
                    nuvo_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=SegNeRF%3A+3D+Part+Segmentation+with+Neural+Radiance+Fields&btnG=">
                    <span class="papertitle">SegNeRF: 3d part segmentation with neural radiance fields</span>
                  </a>
                  <br>
                  <strong>Sara Rojas*</strong>,
                  <a href="https://scholar.google.com/citations?user=DWis350AAAAJ&hl=en">Jesus Zarzar*</a>,
                  <a href="https://scholar.google.com/citations?user=2kq5Zl0AAAAJ&hl=en">Silvio Giancola</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <br>
                  <em>arXiv</em>, 2022
                  <br>
                  <!-- <a href="https://pratulsrinivasan.github.io/nuvo/">project page</a>
                  /
                  <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>
                  / -->
                  <a href="https://arxiv.org/abs/2211.11215">arXiv</a>
                  <p></p>
                  <p>
                    A neural field representation that integrates a semantic field along with the usual radiance field.
                    SegNeRF inherits from previous works the ability to perform novel view synthesis and 3D
                    reconstruction, and enables 3D part segmentation from a few images.
                  </p>
                </td>
              </tr>

              <tr onmouseout="eclipse_stop()" onmouseover="eclipse_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='eclipse_image'>
                    </div>
                      <div></div> -->
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/AdvPC.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                    <!-- <div></div><img src='images/AdvPC.png' width="160"></div> -->
                    <!-- <img src='images/AdvPC.png' width="160"> -->
                  </div>
                  <script type="text/javascript">
                    function eclipse_start() {
                      document.getElementById('eclipse_image').style.opacity = "1";
                    }

                    function eclipse_stop() {
                      document.getElementById('eclipse_image').style.opacity = "0";
                    }
                    eclipse_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/ajhamdi/AdvPC">
                    <span class="papertitle">Advpc: Transferable adversarial perturbations on 3d point clouds</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=tQkWPKAAAAAJ&hl=en">Abdullah Hamdi</a>,
                  <strong>Sara Rojas</strong>,
                  <a href="https://www.alithabet.com/">Ali Thabet</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>, 
                  <br>
                  <em>ECCV</em>, 2020
                  <br>
                  <a href="https://github.com/ajhamdi/AdvPC">Github Repo</a>
                  /
                  <a href="https://www.youtube.com/watch?v=Aq1PPcbhG8Y&feature=youtu.be">video</a>
                  /
                  <a href="https://arxiv.org/abs/1912.00461">arXiv</a>
                  <p></p>
                  <p>
                    We perform transferable adversarial attacks on 3D point clouds by utilizing a point cloud
                    autoencoder. We exceed SOTA by up to 40% on transferability and 38% in breaking SOTA 3D defenses on
                    ModelNet40 data.
                  </p>
                </td>
              </tr>






              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:center;font-size:small;">
                        Kudos to <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing his website template.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
    </tbody>
  </table>

</body>

</html>