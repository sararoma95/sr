<!DOCTYPE HTML>
<html lang="en">


<!-- NOTE: Do not scrape the code from this page directly, as it includes analytics tags. You are welcome to use the HTML in this page, but please do so by cloning the github repo linked at the bottom. -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-QSFRPR5L7E"></script> -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-QSFRPR5L7E');
</script>

<head>
  <!-- Google Tag Manager -->
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-KCT7G6PM');</script>
  <!-- End Google Tag Manager -->
  <meta name="google-site-verification" content="33YsupeCdDQ-bfIMjbNswWCJqA_2Ysw32OzerQgpyv4" />
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Sara Rojas</title>

  <meta name="author" content="Sara Rojas">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KCT7G6PM"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Sara Rojas
                  </p>
                  <p>
                    I'm a PhD Candidate at <a
                      href="https://cemse.kaust.edu.sa/ece/people/person/sara-rojas-martinez">KAUST</a> in Saudi Arabia,
                    under the supervision of Professor <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>.
                  </p>
                  <p>
                    Experience in 3D computer vision: neural rendering, 3D reconstruction, 3D-based recognition tasks, diffusion models and
                    robustness.
                  </p>
                  <p>
                  </p>
                  <p>
                    I've recently completed a research internship at <strong>Naver Labs Europe</strong>, where I worked on extending <a href="https://github.com/naver/mast3r">MAST3R</a> to better understand human behavior. I was fortunate to be advised by <a href="https://europe.naverlabs.com/people_user_naverlabs/gregory-rogez/">Gregory Rogez</a>, <a href="https://europe.naverlabs.com/people_user_naverlabs/matthieu-armando/">Matthieu Armando</a>, and <a href="https://europe.naverlabs.com/people_user_naverlabs/vincent-leroy/">Vincent Leroy</a>.
                  </p>

                  <p>
                    Prior to that, I interned at <strong>Adobe Research</strong>, where I worked under the guidance of <a href="https://www.kalyans.org/">Kalyan Sunkavalli</a>. I also collaborated with <strong>Reality Labs at Meta</strong> in Zurich, mentored by <a href="https://www.albertpumarola.com/">Albert Pumarola</a> and <a href="https://www.alithabet.com/">Ali Thabet</a>. Earlier, I conducted research at the <strong>University of Southern California</strong> with <a href="https://scholar.google.com/citations?user=l_kICksAAAAJ&hl=en">Autumn Kulaga</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:sara.rojasmartinez@kaust.edu.sa">Email</a> &nbsp;/&nbsp;
                    <a href="data/SaraRojas-CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=7vnDKiwAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/SarisRo">X</a> &nbsp;/&nbsp;
                    <a href="https://github.com/sararoma95">Github</a>
                  </p>
                   <p style="text-align:center">
                   Last updated: <strong>April 2025</strong>
                   </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/SaraRojas.jpeg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/SaraRojas.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I’m interested in 3D computer vision, deep learning, generative AI, and image processing. 
                    Most of my research focuses on NeRF and its applications, including scene editing and efficiency. 
                    Lately, I’ve been working on 3D reconstruction.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='datenerf_image'><img src='images/datenerf.png' width=100%></div> -->
                    <img src='images/datenerf.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('datenerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('datenerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://datenerf.github.io/DATENeRF/">
                    <span class="papertitle">DATENeRF: Depth-Aware Text-based Editing of NeRFs</span>
                  </a>
                  <br>
                  <strong>Sara Rojas</strong>,
                  <a href="https://julienphilip.com/">Julien Philip</a>,
                  <a href="https://kai-46.github.io/website/">Kai Zhang</a>,
                  <a href="https://sai-bi.github.io/">Sai Bi</a>,
                  <a href="https://luanfujun.com/">Fujun Luan</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <a href="http://www.kalyans.org/">Kalyan Sunkavalli</a>,
                  <br>
                  <!-- <em>ICCV</em>, 2023 -->
                  <em>ECCV</em>, 2024
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://datenerf.github.io/DATENeRF/">Project Page</a>
                  /
                  <a href="https://arxiv.org/abs/2404.04526">arXiv</a>
                  <p></p>
                  <p>
                    We introduce an inpainting approach that leverages the depth information of NeRF scenes to
                    distribute 2D edits across different images, ensuring robustness against errors and resampling
                    challenges.
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='datenerf_image'><img src='images/datenerf.png' width=100%></div> -->
                    <img src='images/tracknerf.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('datenerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('datenerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://tracknerf.github.io/">
                    <span class="papertitle">TrackNeRF: Bundle Adjusting NeRF from Sparse and Noisy Views via Feature Tracks</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=ksCEO0IAAAAJ&hl=en">Jinjie Mai</a>,
                  <a href="https://ivul.kaust.edu.sa/profiles/wenxuan-zhu">Wenxuan Zhu</a>,
                  <strong>Sara Rojas</strong>,
                  <a href="https://scholar.google.com/citations?user=DWis350AAAAJ&hl=en">Jesus Zarzar</a>,
                  <a href="https://abdullahamdi.com/">Abdullah Hamdi</a>,
                  <a href="https://guochengqian.github.io/">Guocheng Qian</a>,
                  <a href="https://scholar.google.com/citations?user=xBiftlUAAAAJ&hl=en">Bing Li</a>,
                  <a href="https://www.silviogiancola.com/">Silvio Giancola</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem </a>,
                  <br>
                  <!-- <em>ICCV</em>, 2023 -->
                  <em>ECCV</em>, 2024
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://tracknerf.github.io/">Project Page</a>
                  /
                  <a href="https://arxiv.org/abs/2408.10739">arXiv</a>
                  <p></p>
                  <p>
                    TrackNeRF enhances NeRF reconstruction under sparse and noisy poses by enforcing global 3D consistency 
                    via feature tracks across views, inspired by bundle adjustment. It outperforms prior methods like BARF and SPARF, 
                    setting a new benchmark in challenging scenarios.
                  </p>
                </td>
              </tr>
              
              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='smerf_image'><img src='images/re-rend_2.gif' width=100%></div> -->
                    <img src='images/re-rend.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/sararoma95/Re-ReND">
                    <span class="papertitle">Re-ReND: Real-time rendering of nerfs across devices</span>
                  </a>
                  <br>
                  <strong>Sara Rojas</strong>,
                  <a href="https://scholar.google.com/citations?user=DWis350AAAAJ&hl=en">Jesus Zarzar</a>,
                  <a href="https://scholar.google.com/citations?user=zBbUubUAAAAJ&hl=en">Juan C. Perez</a>,
                  <a href="https://scholar.google.de/citations?user=3JmMPIEAAAAJ&hl=en">Artsiom Sanakoyeu</a>,
                  <a href="https://www.alithabet.com/">Ali Thabet</a>,
                  <a href="https://www.albertpumarola.com/">Albert Pumarola</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <br>
                  <em>ICCV</em>, 2023
                  <br>
                  <!-- <a href="https://smerf-3d.github.io/">project page</a>
                  / -->
                  <a href="https://github.com/sararoma95/Re-ReND">Github Repo</a>
                  /
                  <a href="https://arxiv.org/abs/2303.08717">arXiv</a>
                  <p></p>
                  <p>
                    Re-ReND distills the NeRF by extracting the learned density into a mesh, while the
                    learned color information is factorized into a set of matrices that represent the scene's light
                    field. Re-ReND can achieve over a 2.6-fold increase in rendering speed versus the SOTA.
                  </p>
                </td>
              </tr>


              <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='nuvo_image'><video width=100% muted autoplay loop>
                        <source src="images/segnerf.gif" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div> -->
                    <!-- <div class="two" id='nuvo_image'>
                      <img src='images/segnerf.png' width=100%>
                    </div> -->
                    <img src='images/segnerf.gif' width=100%>
                  </div>
                  <!-- <script type="text/javascript">
                    function nuvo_start() {
                      document.getElementById('nuvo_image').style.opacity = "1";
                    }

                    function nuvo_stop() {
                      document.getElementById('nuvo_image').style.opacity = "0";
                    }
                    nuvo_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=SegNeRF%3A+3D+Part+Segmentation+with+Neural+Radiance+Fields&btnG=">
                    <span class="papertitle">SegNeRF: 3d part segmentation with neural radiance fields</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=DWis350AAAAJ&hl=en">Jesus Zarzar*</a>,
                  <strong>Sara Rojas*</strong>,
                  <a href="https://scholar.google.com/citations?user=2kq5Zl0AAAAJ&hl=en">Silvio Giancola</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
                  <br>
                  <em>arXiv</em>, 2022
                  <br>
                  <!-- <a href="https://pratulsrinivasan.github.io/nuvo/">project page</a>
                  /
                  <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>
                  / -->
                  <a href="https://arxiv.org/abs/2211.11215">arXiv</a>
                  <p></p>
                  <p>
                    A neural field representation that integrates a semantic field along with the usual radiance field.
                    SegNeRF inherits from previous works the ability to perform novel view synthesis and 3D
                    reconstruction, and enables 3D part segmentation from a few images.
                  </p>
                </td>
              </tr>

              <tr onmouseout="eclipse_stop()" onmouseover="eclipse_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='eclipse_image'>
                    </div>
                      <div></div> -->
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/AdvPC.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                    <!-- <div></div><img src='images/AdvPC.png' width="160"></div> -->
                    <!-- <img src='images/AdvPC.png' width="160"> -->
                  </div>
                  <script type="text/javascript">
                    function eclipse_start() {
                      document.getElementById('eclipse_image').style.opacity = "1";
                    }

                    function eclipse_stop() {
                      document.getElementById('eclipse_image').style.opacity = "0";
                    }
                    eclipse_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/ajhamdi/AdvPC">
                    <span class="papertitle">Advpc: Transferable adversarial perturbations on 3d point clouds</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=tQkWPKAAAAAJ&hl=en">Abdullah Hamdi</a>,
                  <strong>Sara Rojas</strong>,
                  <a href="https://www.alithabet.com/">Ali Thabet</a>,
                  <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>, <br>
                  <br>
                  <em>ECCV</em>, 2020
                  <br>
                  <a href="https://github.com/ajhamdi/AdvPC">Github Repo</a>
                  /
                  <a href="https://www.youtube.com/watch?v=Aq1PPcbhG8Y&feature=youtu.be">video</a>
                  /
                  <a href="https://arxiv.org/abs/1912.00461">arXiv</a>
                  <p></p>
                  <p>
                    We perform transferable adversarial attacks on 3D point clouds by utilizing a point cloud
                    autoencoder. We exceed SOTA by up to 40% on transferability and 38% in breaking SOTA 3D defenses on
                    ModelNet40 data.
                  </p>
                </td>
              </tr>






              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:center;font-size:small;">
                        Kudos to <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing his website template.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
    </tbody>
  </table>

</body>

</html>